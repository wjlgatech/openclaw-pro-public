# LLM Provider Configuration
# Choose your AI provider: ollama (local, free) | anthropic | openai
LLM_PROVIDER=ollama

# Ollama Configuration (Default - No API key needed!)
# Install Ollama from: https://ollama.ai/download
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Anthropic API Key (Optional - only if using Anthropic)
# Get from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# OpenAI API Key (Optional - only if using OpenAI)
# Get from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-...

# Dashboard Authentication (optional for dev, required for production)
REQUIRE_AUTH=false
DASHBOARD_USERNAME=admin
DASHBOARD_PASSWORD=change-this-in-production

# Server Configuration
ENTERPRISE_PORT=19000
GATEWAY_PORT=18789
LOG_LEVEL=info
NODE_ENV=development

# Database & Storage
USER_ROLES_FILE=./data/user-roles.json
AUDIT_LOG_PATH=./logs/audit.jsonl
DATA_DIR=./data

# Enterprise Features (can be configured via setup wizard)
ENABLE_PII_DETECTION=true
ENABLE_AUDIT_LOGGING=true
ENABLE_MULTI_TENANT=false

# Performance
MAX_CONCURRENT_TASKS=10
TASK_TIMEOUT_MS=300000
